{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_csv = './data/apps_new.csv'\n",
    "lib_csv = './data/libs_new.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "app_df = pd.read_csv(app_csv,sep='::')\n",
    "lib_df = pd.read_csv(lib_csv,sep='::')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "reg = r'[^0-9a-zA-Z]+'\n",
    "reg= re.compile(reg)\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import defaultdict,Counter\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts,build_dic = True):\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    # punctuations\n",
    "    punctuations = [',', '.', ':', ';', '?', '(', ')', '[', ']', '&', '!', '*', '@', '#', '$', '%', '\\'']\n",
    "\n",
    "    # tokenize\n",
    "    # tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    # raw_tokens = tokenizer.tokenize(doc.lower())\n",
    "    # raw_tokens = word_tokenize(doc.lower())\n",
    "\n",
    "    texts = word_tokenize(texts.lower())\n",
    "    # texts = [\n",
    "    #   word_tokenize(doc.lower())\n",
    "    #   for doc in docs\n",
    "    # ]\n",
    "\n",
    "    # stop_words and punctuations\n",
    "    texts = [w for w in texts if not w in stop_words+punctuations]\n",
    "    # texts = [\n",
    "      # [w for w in text if not w in stop_words + punctuations]\n",
    "      # for text in texts\n",
    "    # ]\n",
    "\n",
    "    # remove words that appear only once\n",
    "    if not hasattr(preprocess,'frequency'):\n",
    "        preprocess.frequency = Counter()\n",
    "        frequency =  preprocess.frequency\n",
    "    else:\n",
    "        frequency =  preprocess.frequency\n",
    "        \n",
    "    frequency.update(texts)\n",
    "    # for text in texts:\n",
    "    if build_dic:\n",
    "        return \n",
    "    \n",
    "    \n",
    "    texts = [token for token in texts if frequency[token] >1]\n",
    "\n",
    "    # word stem\n",
    "    ps = PorterStemmer()\n",
    "    # texts = [\n",
    "    texts = [ps.stem(w) for w in texts]\n",
    "      # for text in texts\n",
    "    # ]\n",
    "    if not texts:\n",
    "        texts.append('None-Text')\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       None\n",
       "1       None\n",
       "2       None\n",
       "3       None\n",
       "4       None\n",
       "5       None\n",
       "6       None\n",
       "7       None\n",
       "8       None\n",
       "9       None\n",
       "10      None\n",
       "11      None\n",
       "12      None\n",
       "13      None\n",
       "14      None\n",
       "15      None\n",
       "16      None\n",
       "17      None\n",
       "18      None\n",
       "19      None\n",
       "20      None\n",
       "21      None\n",
       "22      None\n",
       "23      None\n",
       "24      None\n",
       "25      None\n",
       "26      None\n",
       "27      None\n",
       "28      None\n",
       "29      None\n",
       "        ... \n",
       "5244    None\n",
       "5245    None\n",
       "5246    None\n",
       "5247    None\n",
       "5248    None\n",
       "5249    None\n",
       "5250    None\n",
       "5251    None\n",
       "5252    None\n",
       "5253    None\n",
       "5254    None\n",
       "5255    None\n",
       "5256    None\n",
       "5257    None\n",
       "5258    None\n",
       "5259    None\n",
       "5260    None\n",
       "5261    None\n",
       "5262    None\n",
       "5263    None\n",
       "5264    None\n",
       "5265    None\n",
       "5266    None\n",
       "5267    None\n",
       "5268    None\n",
       "5269    None\n",
       "5270    None\n",
       "5271    None\n",
       "5272    None\n",
       "5273    None\n",
       "Name: description, Length: 5274, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_df['description'].apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [``, readi, learn, polish, welcom, babbel, dis...\n",
       "1       [doctor, need, farm, look, littl, anim, look, ...\n",
       "2       ['easi, fast, personalized\\nfind, need, pagine...\n",
       "3       [``, aaj, tak, india, 's, watch, news, channel...\n",
       "4       [note, businfo, merg, businfong, becom, progra...\n",
       "5       [``, walk, band, music, studio, toolkit, virtu...\n",
       "6       [``, start, never, abl, stop, fall, love, conn...\n",
       "7       ['矛掳赂矛\\x97卢毛搂\\x8c, 铆\\x95麓毛\\x8f\\x84, 毛\\xa0\\x88矛...\n",
       "8       ['asphalt, moto, 3d, motor, race, game, simpl,...\n",
       "9       ['thi, game, romanian, language.\\n\\n, '', rasp...\n",
       "10      [``, galaxi, parallax, live, wallpap, nebula, ...\n",
       "11      ['use, desjardin, mobil, servic, make, standar...\n",
       "12      ['googl, authent, gener, 2-step, verif, code, ...\n",
       "13      [``, tuba.fm, free, music, app, smartphon, fin...\n",
       "14      ['sticki, note, ultim, applic, creat, sticki, ...\n",
       "15      ['blick, sport, 芒\\x80\\x93, die, sport-app, der...\n",
       "16      [``, no.1, mobil, research, survey, applic, ov...\n",
       "17      ['play, newest, shoot-bubbl, style, game, make...\n",
       "18      [``, introduc, prize, claw, \\n\\nfor, year, 've...\n",
       "19      ['do脜\\x82脛\\x85cz, najwi脛\\x99kszej, spo脜\\x82ecz...\n",
       "20      ['make, space, issu, matter, guardian, app, gi...\n",
       "21      ['5茫\\x81隆茫\\x82\\x83茫\\x82\\x93茫\\x81\\xad茫\\x82\\x8b,...\n",
       "22      [``, 芒\\x98\\x85芒\\x98\\x85芒\\x98\\x85what, 's, word...\n",
       "23      ['find, einfach, und, schnell, herau, woher, e...\n",
       "24      ['the, excit, new, chapter, captiv, time, mana...\n",
       "25      [``, fml, around, almost, 10, year, give, take...\n",
       "26      ['with, 30, million, user, per, month, largest...\n",
       "27      ['lleva, contigo, en, tu, android, la, santa, ...\n",
       "28      ['download, new, applic, rtl, 102.5, android, ...\n",
       "29      [``, music, equal, -, best, music, eq, android...\n",
       "                              ...                        \n",
       "5244    [芒\\x98\\x85矛\\x95\\xa0毛\\x8b\\x88铆\\x8c隆, 矛\\x82卢矛虏\\x...\n",
       "5245    [``, hit, game, hangman, delux, premium, final...\n",
       "5246    ['play, best, fun, game, discov, new, free, mo...\n",
       "5247    [``, look, gadget, offbeat, gift, idea, china-...\n",
       "5248    ['**, cnet, ``, ..., siri, breadth, robin, dep...\n",
       "5249    ['tri, mani, differ, eye, color, eye, effect, ...\n",
       "5250    ['aplicativo, ofici, do, cart脙碌, alelo, benef脙...\n",
       "5251    ['hustl, cash, level, play, tournament, becom,...\n",
       "5252    ['the, year, 1852., crack, team, scientist, le...\n",
       "5253    [``, reclaim, camelot, black, knight, join, th...\n",
       "5254    ['emanc, borderlin, war, combin, massiv, battl...\n",
       "5255    ['from, creator, tini, tower, sky, burger, poc...\n",
       "5256    [芒\\x98\\x85classic, puzzl, game芒\\x98\\x85, tap, ...\n",
       "5257    ['the, offici, hotukd, app, access, deal, vouc...\n",
       "5258    [``, drive, car, desert, highway, zombi, leap,...\n",
       "5259    [``, talk, gingerbread, man, let, interact, me...\n",
       "5260    ['flick, name, app, \\n\\n茫\\x80\\x90featur, flick...\n",
       "5261    [``, rank, top, 10, free, lifestyl, app\\n\\n3, ...\n",
       "5262    ['cook, like, chef, \\nmore, 100.000, recip, fr...\n",
       "5263    ['*, wire, -, essenti, app, telegraph, -, must...\n",
       "5264    ['tv, movi, die, best, app, f脙录r, ihr, tv, pro...\n",
       "5265    [``, virtual, hors, race, 3d, realist, 3d, hor...\n",
       "5266    [``, love, candi, right, cute, littl, creatur,...\n",
       "5267    ['e, totalment, en, espa脙卤ol, clasificada, en,...\n",
       "5268    ['stand, livescor, fixtur, ..., \\n\\nfast, live...\n",
       "5269    ['thi, interest, princess, game, children/kid,...\n",
       "5270    ['mahjong, delux, free, solitair, game, base, ...\n",
       "5271    ['enjoy, 6, level, free, version, wed, dash, 1...\n",
       "5272    [``, matter, 're, look, travel, travelpirates....\n",
       "5273    ['la, biblia, cat脙鲁lica, edici脙鲁n, latinoameri...\n",
       "Name: description, Length: 5274, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_df['description'].apply(preprocess,build_dic = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del preprocess.frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reprocess_df(df):\n",
    "    df = df.set_index('kgid')\n",
    "    df['description'].apply(preprocess)\n",
    "    df['description'] = df['description'].apply(preprocess,build_dic = False)\n",
    "    #df['description']= df['description'].apply(lambda x: reg.sub(\" \",x))\n",
    "    #df['description'] = df['description'].apply(str.split)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_df = reprocess_df(app_df)\n",
    "lib_df = reprocess_df(lib_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lda_text(dataframe):\n",
    "    texts = []\n",
    "    for des in dataframe['description']:\n",
    "        texts.append(des)\n",
    "    return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_text = load_lda_text(app_df)\n",
    "lib_text = load_lda_text(lib_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_text = app_text #+ lib_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.corpora.dictionary import Dictionary as gen_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_dict = gen_dict(lda_text)\n",
    "lda_corpus = [lda_dict.doc2bow(text) for text in lda_text]\n",
    "lda_model = LdaMulticore(lda_corpus,num_topics= 300,id2word=lda_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "model_path = r'./data/lda_datas/lda.model'\n",
    "dict_path = r'./data/lda_datas/lda.dict'\n",
    "lda_dict.save(dict_path)\n",
    "lda_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_df.to_hdf('./data/app_dfs',key = 'app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lib_df.to_hdf('./data/lib_dfs',key = 'lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([app_df,lib_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui2index = pickle.load(open('./data/ui2index','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.set_index('kgid')\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df['kgid'].apply(lambda x: ui2index[str(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2377: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['description']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df.to_hdf('./data/id2text',key ='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.loc[5]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = lda_dict.doc2bow(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5274"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_df.size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
